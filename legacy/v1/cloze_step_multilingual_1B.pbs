#!/bin/bash
#PBS -P CFP01-CF-060
#PBS -j oe
#PBS -k oed
#PBS -N llm-latent-cloze-step
#PBS -M e1583535@u.nus.edu
#PBS -q auto
#PBS -m abe
#PBS -l select=1:ngpus=2
#PBS -l walltime=96:00:00

cd $PBS_O_WORKDIR;

image="/app1/common/singularity-img/hopper/pytorch/pytorch_2.3.0_cuda_12.4_ngc_24.04.sif"

module load singularity

LOG_DIR=./logs/cloze_steps
mkdir -p $LOG_DIR

singularity exec -e \
--env HF_HOME=/scratch/e1583535/cache \
--env HF_DATASETS_CACHE=/scratch/e1583535/cache/datasets \
$image bash << EOF > $LOG_DIR/stdout.$PBS_JOBID.log 2> $LOG_DIR/stderr.$PBS_JOBID.log

python -c "import gc, torch; torch.cuda.empty_cache(); gc.collect()"

source /hpctmp/e1583535/virtualenvs/lm-latent/bin/activate

echo "Starting training at $(date)"
echo "Running on host: $(hostname)"
echo "GPU info:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits || echo "No GPU detected"

python cloze_step.py \
  --target_lang zh \
  --data_prefix /scratch/e1583535/llm-latent-language/data/langs \
  --out_dir /scratch/e1583535/llm-latent-language/visuals/multilingual-1B \
  --checkpoints "
  /scratch/e1583535/llm/nus-olmo/multilingual-n10B-7.5-replay-2.5-checkpoints/step954-unsharded-hf, \
  /scratch/e1583535/llm/nus-olmo/multilingual-n10B-7.5-replay-2.5-checkpoints/step1908-unsharded-hf, \
  /scratch/e1583535/llm/nus-olmo/multilingual-n10B-7.5-replay-2.5-checkpoints/step2862-unsharded-hf, \
  /scratch/e1583535/llm/nus-olmo/multilingual-n10B-7.5-replay-2.5-checkpoints/step3816-unsharded-hf,
  /scratch/e1583535/llm/nus-olmo/multilingual-n10B-7.5-replay-2.5-checkpoints/step4770-unsharded-hf-multilingual" \
  --steps 2B,4B,6B,8B,10B \
  --layers 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16 \
  --no_load_in_8bit

# you can put more commands here
echo "Done"

EOF